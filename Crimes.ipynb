{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'12/31/2012,120418722,12/31/2012,800,4,Hollenbeck,453,510,VEHICLE - STOLEN,IC,Invest Cont, 1400    WARREN                       ST,,\"(34.0515, -118.2201)\"']\n",
      "238117\n",
      "[u'03/20/2013,132007717,03/20/2013,2015,20,Olympic,2004,997,TRAFFIC DR #,UNK,Unknown,              OXFORD,   OAKWOOD,\"(34.0776, -118.308)\"']\n",
      "239731\n",
      "[u'08/23/2014,140119745,08/23/2014,2240,1,Central,111,310,BURGLARY,IC,Invest Cont,  500      N  FIGUEROA                     ST,,\"(34.0617, -118.2469)\"']\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "\n",
    "#Crimes_2012-2015\n",
    "#https://catalog.data.gov/dataset/crimes-2012-2015\n",
    "\n",
    "# 935259 Rows\n",
    "# 2012 - 2015\n",
    "#Header = Date.Rptd, DR.NO,DATE.OCC,TIME.OCC,AREA,AREA.NAME,RD,Crm.Cd,CrmCd.Desc,Status,Status.Desc,\n",
    "#            LOCATION,Cross.Street,Location.1\n",
    "#AREA.NAME = districten\n",
    "\n",
    "\n",
    "years =[]\n",
    "\n",
    "#import dataset (pas locatie aan)\n",
    "#filter header eruit\n",
    "crime_data = (sc.textFile('../Crimes_2012-2015.csv').filter(lambda line: 'DATE.OCC' not in line))\n",
    "\n",
    "\n",
    "for i in range(12, 16, 1):\n",
    "    y = '20' + str(i)\n",
    "    year = crime_data.filter(lambda line: '/' + y in line)\n",
    "    years.append(year)\n",
    "    print year.take(1)\n",
    "    \n",
    "    print years[i-12].count()\n",
    "\n",
    "for i in range(12,16, 1):\n",
    "    print years[i].count()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228443\n",
      "228443\n",
      "228443\n",
      "228443\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdYAAAHaCAYAAAC92GghAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npIYMVkmSGvr/Cu0BV4E+DsEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x91f6e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# x_axis = [ for i in range(12, 16, 1)]\n",
    "\n",
    "x_axis = []\n",
    "y_axis = []\n",
    "\n",
    "for i in range(0, 4):\n",
    "#     try:\n",
    "#     y = i-12\n",
    "    x_axis.append(i)\n",
    "    y_axis.append(years[i].count())\n",
    "    print years[i].count()\n",
    "        \n",
    "#     except:\n",
    "#         y_axis.append(0)\n",
    "#         print 'test'\n",
    "       \n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "fig.suptitle('Crimes per year', fontsize=14)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlabel('years')\n",
    "ax.set_ylabel('crimes')\n",
    "ax.bar(x_axis, y_axis, fc='darksalmon', align='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SQLContext' object has no attribute 'show'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-c06882dae659>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msqlContext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSQLContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msqlContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'SQLContext' object has no attribute 'show'"
     ]
    }
   ],
   "source": [
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o23.applySchemaToPythonRDD.\n: java.lang.RuntimeException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient\r\n\tat org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:522)\r\n\tat org.apache.spark.sql.hive.client.HiveClientImpl.<init>(HiveClientImpl.scala:171)\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\r\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\r\n\tat java.lang.reflect.Constructor.newInstance(Unknown Source)\r\n\tat org.apache.spark.sql.hive.client.IsolatedClientLoader.createClient(IsolatedClientLoader.scala:258)\r\n\tat org.apache.spark.sql.hive.HiveUtils$.newClientForMetadata(HiveUtils.scala:359)\r\n\tat org.apache.spark.sql.hive.HiveUtils$.newClientForMetadata(HiveUtils.scala:263)\r\n\tat org.apache.spark.sql.hive.HiveSharedState.metadataHive$lzycompute(HiveSharedState.scala:39)\r\n\tat org.apache.spark.sql.hive.HiveSharedState.metadataHive(HiveSharedState.scala:38)\r\n\tat org.apache.spark.sql.hive.HiveSharedState.externalCatalog$lzycompute(HiveSharedState.scala:46)\r\n\tat org.apache.spark.sql.hive.HiveSharedState.externalCatalog(HiveSharedState.scala:45)\r\n\tat org.apache.spark.sql.hive.HiveSessionState.catalog$lzycompute(HiveSessionState.scala:50)\r\n\tat org.apache.spark.sql.hive.HiveSessionState.catalog(HiveSessionState.scala:48)\r\n\tat org.apache.spark.sql.hive.HiveSessionState$$anon$1.<init>(HiveSessionState.scala:63)\r\n\tat org.apache.spark.sql.hive.HiveSessionState.analyzer$lzycompute(HiveSessionState.scala:63)\r\n\tat org.apache.spark.sql.hive.HiveSessionState.analyzer(HiveSessionState.scala:62)\r\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:49)\r\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:64)\r\n\tat org.apache.spark.sql.SparkSession.applySchemaToPythonRDD(SparkSession.scala:666)\r\n\tat org.apache.spark.sql.SparkSession.applySchemaToPythonRDD(SparkSession.scala:656)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:280)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:211)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient\r\n\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1523)\r\n\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:86)\r\n\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:132)\r\n\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\r\n\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3005)\r\n\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3024)\r\n\tat org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:503)\r\n\t... 32 more\r\nCaused by: java.lang.reflect.InvocationTargetException\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\r\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\r\n\tat java.lang.reflect.Constructor.newInstance(Unknown Source)\r\n\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1521)\r\n\t... 38 more\r\nCaused by: java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative path in absolute URI: file:C:/spark/bin/spark-warehouse\r\n\tat org.apache.hadoop.fs.Path.initialize(Path.java:205)\r\n\tat org.apache.hadoop.fs.Path.<init>(Path.java:171)\r\n\tat org.apache.hadoop.hive.metastore.Warehouse.getWhRoot(Warehouse.java:159)\r\n\tat org.apache.hadoop.hive.metastore.Warehouse.getDefaultDatabasePath(Warehouse.java:177)\r\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB_core(HiveMetaStore.java:600)\r\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:620)\r\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:461)\r\n\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:66)\r\n\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72)\r\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5762)\r\n\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:199)\r\n\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:74)\r\n\t... 43 more\r\nCaused by: java.net.URISyntaxException: Relative path in absolute URI: file:C:/spark/bin/spark-warehouse\r\n\tat java.net.URI.checkPath(Unknown Source)\r\n\tat java.net.URI.<init>(Unknown Source)\r\n\tat org.apache.hadoop.fs.Path.initialize(Path.java:202)\r\n\t... 54 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-2534ec02d4c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0myear\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'20'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     \u001b[0mconvert_to_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregisterTempTable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYEAR\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_table'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[0msql\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'SELECT COUNT(*) AS CNT FROM '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mYEAR\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_table'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mcrime_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msqlContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-2534ec02d4c9>\u001b[0m in \u001b[0;36mconvert_to_df\u001b[1;34m(year)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;31m# apply the schema to the RDD.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0myear_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msqlContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myear_rdd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0myear_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\python\\pyspark\\sql\\context.pyc\u001b[0m in \u001b[0;36mcreateDataFrame\u001b[1;34m(self, data, schema, samplingRatio)\u001b[0m\n\u001b[0;32m    297\u001b[0m         \u001b[0mPy4JJavaError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m         \"\"\"\n\u001b[1;32m--> 299\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0msince\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\python\\pyspark\\sql\\session.pyc\u001b[0m in \u001b[0;36mcreateDataFrame\u001b[1;34m(self, data, schema, samplingRatio)\u001b[0m\n\u001b[0;32m    522\u001b[0m             \u001b[0mrdd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mschema\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_createFromLocal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m         \u001b[0mjrdd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerDeUtil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoJavaArray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_to_java_object_rdd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 524\u001b[1;33m         \u001b[0mjdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplySchemaToPythonRDD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjrdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    525\u001b[0m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_schema\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\python\\lib\\py4j-0.10.1-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m         return_value = get_return_value(\n\u001b[1;32m--> 933\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m    934\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\python\\pyspark\\sql\\utils.pyc\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\python\\lib\\py4j-0.10.1-src.zip\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    310\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    311\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    313\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o23.applySchemaToPythonRDD.\n: java.lang.RuntimeException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient\r\n\tat org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:522)\r\n\tat org.apache.spark.sql.hive.client.HiveClientImpl.<init>(HiveClientImpl.scala:171)\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\r\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\r\n\tat java.lang.reflect.Constructor.newInstance(Unknown Source)\r\n\tat org.apache.spark.sql.hive.client.IsolatedClientLoader.createClient(IsolatedClientLoader.scala:258)\r\n\tat org.apache.spark.sql.hive.HiveUtils$.newClientForMetadata(HiveUtils.scala:359)\r\n\tat org.apache.spark.sql.hive.HiveUtils$.newClientForMetadata(HiveUtils.scala:263)\r\n\tat org.apache.spark.sql.hive.HiveSharedState.metadataHive$lzycompute(HiveSharedState.scala:39)\r\n\tat org.apache.spark.sql.hive.HiveSharedState.metadataHive(HiveSharedState.scala:38)\r\n\tat org.apache.spark.sql.hive.HiveSharedState.externalCatalog$lzycompute(HiveSharedState.scala:46)\r\n\tat org.apache.spark.sql.hive.HiveSharedState.externalCatalog(HiveSharedState.scala:45)\r\n\tat org.apache.spark.sql.hive.HiveSessionState.catalog$lzycompute(HiveSessionState.scala:50)\r\n\tat org.apache.spark.sql.hive.HiveSessionState.catalog(HiveSessionState.scala:48)\r\n\tat org.apache.spark.sql.hive.HiveSessionState$$anon$1.<init>(HiveSessionState.scala:63)\r\n\tat org.apache.spark.sql.hive.HiveSessionState.analyzer$lzycompute(HiveSessionState.scala:63)\r\n\tat org.apache.spark.sql.hive.HiveSessionState.analyzer(HiveSessionState.scala:62)\r\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:49)\r\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:64)\r\n\tat org.apache.spark.sql.SparkSession.applySchemaToPythonRDD(SparkSession.scala:666)\r\n\tat org.apache.spark.sql.SparkSession.applySchemaToPythonRDD(SparkSession.scala:656)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:280)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:211)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient\r\n\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1523)\r\n\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:86)\r\n\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:132)\r\n\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\r\n\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3005)\r\n\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3024)\r\n\tat org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:503)\r\n\t... 32 more\r\nCaused by: java.lang.reflect.InvocationTargetException\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\r\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\r\n\tat java.lang.reflect.Constructor.newInstance(Unknown Source)\r\n\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1521)\r\n\t... 38 more\r\nCaused by: java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative path in absolute URI: file:C:/spark/bin/spark-warehouse\r\n\tat org.apache.hadoop.fs.Path.initialize(Path.java:205)\r\n\tat org.apache.hadoop.fs.Path.<init>(Path.java:171)\r\n\tat org.apache.hadoop.hive.metastore.Warehouse.getWhRoot(Warehouse.java:159)\r\n\tat org.apache.hadoop.hive.metastore.Warehouse.getDefaultDatabasePath(Warehouse.java:177)\r\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB_core(HiveMetaStore.java:600)\r\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:620)\r\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:461)\r\n\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:66)\r\n\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72)\r\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5762)\r\n\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:199)\r\n\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:74)\r\n\t... 43 more\r\nCaused by: java.net.URISyntaxException: Relative path in absolute URI: file:C:/spark/bin/spark-warehouse\r\n\tat java.net.URI.checkPath(Unknown Source)\r\n\tat java.net.URI.<init>(Unknown Source)\r\n\tat org.apache.hadoop.fs.Path.initialize(Path.java:202)\r\n\t... 54 more\r\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from datetime import datetime\n",
    "\n",
    "#Crimes_2012-2015\n",
    "#https://catalog.data.gov/dataset/crimes-2012-2015\n",
    "\n",
    "# 935259 Rows\n",
    "# 2012 - 2015\n",
    "#Header = Date.Rptd, DR.NO,DATE.OCC,TIME.OCC,AREA,AREA.NAME,RD,Crm.Cd,CrmCd.Desc,Status,Status.Desc,\n",
    "#            LOCATION,Cross.Street,Location.1\n",
    "#AREA.NAME = districten\n",
    "\n",
    "YEARS = [2012, 2013, 2014, 2015]\n",
    "crime_data = []\n",
    "\n",
    "#import dataset (pas locatie aan)\n",
    "#filter header eruit\n",
    "# crime_data = (sc.textFile('../data/crimesLA/Crimes_2012-2015.csv').filter(lambda l: 'DATE.OCC' not in l))\n",
    "\n",
    "# convert to a dataframe\n",
    "def convert_to_df(year):\n",
    "#     if year == '2015-01':\n",
    "#         separator = '\\t'\n",
    "#     else:\n",
    "#         separator = ';'\n",
    "    seperator = \";\"\n",
    "    crime_data = sc.textFile('../Crimes_2012-2015.csv')\n",
    "    year_rdd = (crime_data\n",
    "                    .filter(lambda l: 'DATE.OCC' not in l)\n",
    "                    .filter(lambda l: '/' + year in l)\n",
    "                    .map(lambda l: add_fields(l, separator))\n",
    "               )\n",
    "    \n",
    "    # apply the schema to the RDD.\n",
    "    year_df = sqlContext.createDataFrame(year_rdd, schema)\n",
    "    \n",
    "    return year_df\n",
    "\n",
    "fields = []\n",
    "fields.append(StructField('DateReported', DateType(), True))\n",
    "fields.append(StructField('Docnr', IntegerType(), True))\n",
    "fields.append(StructField('DateOccupied', DateType(), True))\n",
    "fields.append(StructField('areaId', IntegerType(), True))\n",
    "fields.append(StructField('areaName', StringType(), True))\n",
    "fields.append(StructField('rd', IntegerType(), True))\n",
    "fields.append(StructField('crimeId', IntegerType(), True))\n",
    "fields.append(StructField('crimeName', StringType(), True))\n",
    "fields.append(StructField('statusId', IntegerType(), True))\n",
    "fields.append(StructField('statusName', StringType(), True))\n",
    "fields.append(StructField('location', StringType(), True))\n",
    "fields.append(StructField('crossStreet', StringType(), True))\n",
    "fields.append(StructField('location_type', StringType(), True))\n",
    "schema = StructType(fields)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "fields = []\n",
    "fields.append(StructField('DateReported', DateType(), True))\n",
    "fields.append(StructField('Docnr', IntegerType(), True))\n",
    "fields.append(StructField('DateOccupied', DateType(), True))\n",
    "fields.append(StructField('areaId', IntegerType(), True))\n",
    "fields.append(StructField('areaName', StringType(), True))\n",
    "fields.append(StructField('rd', IntegerType(), True))\n",
    "fields.append(StructField('crimeId', IntegerType(), True))\n",
    "fields.append(StructField('crimeName', StringType(), True))\n",
    "fields.append(StructField('statusId', IntegerType(), True))\n",
    "fields.append(StructField('statusName', StringType(), True))\n",
    "fields.append(StructField('location', StringType(), True))\n",
    "fields.append(StructField('crossStreet', StringType(), True))\n",
    "fields.append(StructField('lat', FloatType(), True))\n",
    "fields.append(StructField('long', FloatType(), True))\n",
    "schema = StructType(fields)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_fields(line, separator):\n",
    "    fields = []\n",
    "    vals = line.split(separator)\n",
    "    # DateReported\n",
    "    date = datetime.strptime(vals[0], '%m/%d/%Y')\n",
    "    fields.append(date)\n",
    "    # Docnr\n",
    "    fields.append(int(vals[2]))\n",
    "    # DateOccupied\n",
    "    date = datetime.strptime(vals[3], '%m/%d/%Y')\n",
    "    fields.append(date)\n",
    "    # areaId\n",
    "    fields.append(int(vals[4]))\n",
    "    # areaName\n",
    "    fields.append(vals[3])\n",
    "    # rd\n",
    "    fields.append(int(vals[5]))\n",
    "    # crimeId\n",
    "    fields.append(int(vals[6]))\n",
    "    # crimeName\n",
    "    fields.append(vals[7])\n",
    "    # statusId\n",
    "    fields.append(int(vals[8]))\n",
    "    # statusName\n",
    "    fields.append(vals[9])\n",
    "    # location\n",
    "    fields.append(vals[10])\n",
    "    # crossStreet\n",
    "    fields.append(vals[11])\n",
    "    # lat\n",
    "    fields.append(vals[12][2:])\n",
    "    # longit\n",
    "    fields.append(vals[12][:-2])\n",
    "    \n",
    "    \n",
    "    return fields\n",
    "zz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
